{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1d2EQDy9T59YXfvHtcRGr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamPoe/CSCI-290/blob/main/notebooks/asm_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ThC-lCa0kh35"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, accuracy_score, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Gini_Impurity(df, attribs, target):\n",
        "    gini = 0\n",
        "    lowest_gini = float('inf')\n",
        "    split_point = 0\n",
        "    lowest_quant_gini = float('inf')\n",
        "    quant_attrib = ''\n",
        "    overall = len( df )\n",
        "    for attrib in attribs: ### change this to df.columns ###\n",
        "      vals = df[attrib].unique()\n",
        "      # Quantitative Gini Impurity Calc\n",
        "      if df[attrib].dtype in ['float64', 'int64']:\n",
        "        if len( df[attrib].unique() ) > 10:\n",
        "          vals.sort()\n",
        "          overall = len( df )\n",
        "          gini_impurities = []\n",
        "          for val in vals:\n",
        "            quant_gini = 0\n",
        "            left = df[ df[attrib] <= val ][ [attrib,target] ]\n",
        "            props = left[ target ].value_counts( normalize = True )\n",
        "            weight = len( left ) / overall\n",
        "            for prop in props.array:\n",
        "              quant_gini += weight*(1-(prop**2)) ## Gini calculation\n",
        "            right = df[ df[attrib] > val ][ [attrib,target] ]\n",
        "            props = right[ target ].value_counts( normalize = True )\n",
        "            weight = len( right ) / overall\n",
        "            for prop in props.array:\n",
        "              if prop > 0:\n",
        "                ### Change calculation ###\n",
        "                quant_gini += weight*(1-(prop**2))\n",
        "              gini_impurities.append(quant_gini)\n",
        "          index = pd.Series( gini_impurities ).idxmin()\n",
        "          # Check to see if there is a new lowest Gini Impurity\n",
        "          if gini_impurities[index] < lowest_quant_gini:\n",
        "            # Lowest Gini Impurity\n",
        "            lowest_quant_gini = gini_impurities[index]\n",
        "            # Split point with lowest Gini Impurity\n",
        "            split_point = vals[index]\n",
        "            # Attribute that has the split point\n",
        "            quant_attrib = attrib\n",
        "\n",
        "      # Categorical Gini Impurity Calc\n",
        "      else:\n",
        "        for val in vals:\n",
        "          subset_size = len(df[ df[attrib] == val ])\n",
        "          weight = subset_size / overall\n",
        "          props = df[ df[attrib] == val ][target].value_counts( normalize=True )\n",
        "          for p in props.array:\n",
        "            gini +=  weight*(1-(p**2)) ## Gini calculation\n",
        "        if lowest_gini > gini:\n",
        "          lowest_gini = gini\n",
        "          lowest_attrib = attrib\n",
        "    # Compares the lowest categorical Gini Impurity with the lowest quantitative Gini Impurity\n",
        "    if lowest_gini < lowest_quant_gini:\n",
        "      # If categorical Gini Impurity is still lowest\n",
        "      return lowest_attrib, lowest_gini\n",
        "    else:\n",
        "      # If quantitative Gini Impurity is lowest\n",
        "      lowest_gini = lowest_quant_gini\n",
        "      lowest_attrib = quant_attrib\n",
        "      return lowest_attrib, split_point, lowest_gini"
      ],
      "metadata": {
        "id": "7ehRPlXUE4YM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Entropy (df, attribs, target):\n",
        "    entropy = 0\n",
        "    lowest_entropy = float('inf')\n",
        "    split_point = 0\n",
        "    lowest_quant_entropy = float('inf')\n",
        "    quant_attrib = ''\n",
        "    overall = len( df )\n",
        "    for attrib in attribs: ### change this to df.columns ###\n",
        "      vals = df[attrib].unique()\n",
        "      # Quantitative Entropy Calc\n",
        "      if df[attrib].dtype in ['float64', 'int64']:\n",
        "        if len( df[attrib].unique() ) > 10:\n",
        "          vals.sort()\n",
        "          overall = len( df )\n",
        "          entropies = []\n",
        "          for val in vals:\n",
        "            quant_entropy = 0\n",
        "            left = df[ df[attrib] <= val ][ [attrib,target] ]\n",
        "            props = left[ target ].value_counts( normalize = True )\n",
        "            weight = len( left ) / overall\n",
        "            for prop in props.array:\n",
        "              quant_entropy = quant_entropy - weight*prop*math.log2( prop ) ## Entropy calculation\n",
        "            right = df[ df[attrib] > val ][ [attrib,target] ]\n",
        "            props = right[ target ].value_counts( normalize = True )\n",
        "            weight = len( right ) / overall\n",
        "            for prop in props.array:\n",
        "              if prop > 0:\n",
        "                quant_entropy = quant_entropy - weight*prop*math.log2( prop )\n",
        "              entropies.append(quant_entropy)\n",
        "          index = pd.Series( entropies ).idxmin()\n",
        "          # Check to see if there is a new lowest Entropy\n",
        "          if entropies[index] < lowest_quant_entropy:\n",
        "            # Lowest entropy\n",
        "            lowest_quant_entropy = entropies[index]\n",
        "            # Split point with lowest entropy\n",
        "            split_point = vals[index]\n",
        "            # Attribute that has the split point\n",
        "            quant_attrib = attrib\n",
        "\n",
        "      # Categorical Entropy Calc\n",
        "      else:\n",
        "        for val in vals:\n",
        "          subset_size = len(df[ df[attrib] == val ])\n",
        "          weight = subset_size / overall\n",
        "          props = df[ df[attrib] == val ][target].value_counts( normalize=True )\n",
        "          for prop in props.array:\n",
        "            entropy =  entropy - weight*(prop*math.log2(prop)) ## Entropy calculation\n",
        "        if lowest_entropy > entropy:\n",
        "          lowest_entropy = entropy\n",
        "          lowest_attrib = attrib\n",
        "    # Compares the lowest categorical Entropy with the lowest quantitative Entropy\n",
        "    if lowest_entropy < lowest_quant_entropy:\n",
        "      # If categorical entropy is still lowest\n",
        "      return lowest_attrib, lowest_entropy\n",
        "    else:\n",
        "      # If quantitative entropy is lowest\n",
        "      lowest_entropy = lowest_quant_entropy\n",
        "      lowest_attrib = quant_attrib\n",
        "      return lowest_attrib, split_point, lowest_entropy"
      ],
      "metadata": {
        "id": "Z73cB_7rE4a7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification(X_train, X_test, y_train, y_test, method, pipeline):\n",
        "\n",
        "  ### Gini Impurity method ###\n",
        "  if method == \"gini\":\n",
        "    result = Gini_Impurity(df, X_train, y_train.name)\n",
        "    print(\"Gini Impurity result:\", result)\n",
        "\n",
        "  ### Entropy method ###\n",
        "  elif method == \"entropy\":\n",
        "    result = Entropy(df, X_train, y_train.name)\n",
        "    print(\"Entropy result:\", result)\n",
        "\n",
        "  ### Invalid method ###\n",
        "  else:\n",
        "    print(\"Invalid Method\")\n",
        "    return\n",
        "\n",
        "  ## DecisionTreeClassifier ###\n",
        "\n",
        "  ### Fits the training data to the pipline ###\n",
        "  pipeline.fit(X_train, y_train)\n",
        "  ### Predicts the test data ###\n",
        "  y_pred = pipeline.predict(X_test)\n",
        "  ### Calculates the accuracy score ###\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  ### Plots the decision tree ###\n",
        "  plot_tree(pipeline.named_steps['clf'], filled=True, rounded=True, fontsize=6)\n",
        "  return accuracy\n",
        ""
      ],
      "metadata": {
        "id": "agvv4BCspyNy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### STILL WORKING ON ####\n",
        "def regression(X_train, X_test, y_train, y_test, pipeline):\n",
        "\n",
        "  ### Imputes the missing values in the training data ###\n",
        "\n",
        "  imputer = SimpleImputer(strategy='mean')\n",
        "  X_train = imputer.fit_transform(X_test)\n",
        "  X_test = imputer.transform(y_test)\n",
        "\n",
        "  ### Calculates the mean squared error ###\n",
        "\n",
        "  sqrd_errs = (X_test - y_test)**2\n",
        "  mse = np.mean(sqrd_errs)\n",
        "  print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "  ## DecisionTreeRegressor ##\n",
        "\n",
        "  ### Fits the training data to the pipline ###\n",
        "  pipeline.fit(X_train, y_train)\n",
        "  ### Predicts the test data ###\n",
        "  y_pred = pipeline.predict(X_test)\n",
        "  ### Calculates the mean squared error ###\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  ### Plots the decision tree ###\n",
        "  plot_tree(pipeline.named_steps['clf'], filled=True, rounded=True, fontsize=7)\n",
        "  return \"Mean Squared Error:\", mse\n"
      ],
      "metadata": {
        "id": "ixr2Qg7qpyQV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Attribute_selection_method(task, df, target):\n",
        "\n",
        "  ### Split the data ###\n",
        "  X = df.drop(target, axis=1)\n",
        "  y = df[target]\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "  ### Process the data ###\n",
        "  num_attributes = X_train.select_dtypes( include = ['float64']).columns\n",
        "  cat_attributes = X_train.select_dtypes( include = ['object']).columns\n",
        "\n",
        "  trf = [ ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n",
        "         ('Scaler', StandardScaler())]),\n",
        "         num_attributes), ('cat', OneHotEncoder( handle_unknown='ignore' ), cat_attributes) ]\n",
        "  col_transform = ColumnTransformer( transformers = trf )\n",
        "\n",
        "  ### Classification task ###\n",
        "  if task.lower() == \"classification\":\n",
        "    method = input(\"Enter the method of attribute selection (gini or entropy): \").lower()\n",
        "    ### NOT 100% SURE THIS IS WHAT CAN BE DONE ###\n",
        "    pipeline = Pipeline( steps = [('pre', col_transform),\n",
        "('clf', DecisionTreeClassifier(max_depth=2))])\n",
        "    ### Function call ###\n",
        "    print(classification(X_train, X_test, y_train, y_test, method, pipeline))\n",
        "\n",
        "  ### Regression task ###\n",
        "  elif task.lower() == \"regression\":\n",
        "    ### Pipeline for regression ###\n",
        "    pipeline = Pipeline( steps = [('pre', col_transform),\n",
        "('clf', DecisionTreeRegressor(max_depth = 2))])\n",
        "    ### Function call ###\n",
        "    print(regression(X_train, X_test, y_train, y_test, pipeline))\n",
        "\n",
        "  ### Invalid task ###\n",
        "  else:\n",
        "    print(\"Invalid Task\")\n",
        "    return"
      ],
      "metadata": {
        "id": "poFj0ZAqnLbL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/WilliamPoe/CSCI-290/refs/heads/main/Data/ds_salaries.csv\") ## Dataset\n",
        "#target = \"experience_level\" ## Categorical target attribute\n",
        "target = \"work_year\" ## Numerical target attribute\n",
        "#task = \"classification\" ## For Classification\n",
        "task = \"regression\" ## For Regression\n",
        "Attribute_selection_method(task, df, target)"
      ],
      "metadata": {
        "id": "Q05dsZSeqN3T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "b0cdd127-153a-4326-d64b-2822456c07f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'SE'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-db378fcf88b8>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#task = \"classification\" ## For Classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"regression\"\u001b[0m \u001b[0;31m## For Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mAttribute_selection_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-31dc059fdc54>\u001b[0m in \u001b[0;36mAttribute_selection_method\u001b[0;34m(task, df, target)\u001b[0m\n\u001b[1;32m     30\u001b[0m ('clf', DecisionTreeRegressor(max_depth = 2))])\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m### Function call ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;31m### Invalid task ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-fcd18e70cabb>\u001b[0m in \u001b[0;36mregression\u001b[0;34m(X_train, X_test, y_train, y_test, pipeline)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \"\"\"\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;31m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    346\u001b[0m                     )\n\u001b[1;32m    347\u001b[0m                 )\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'SE'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ozXt8JQJcM3r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}