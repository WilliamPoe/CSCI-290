{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM5GLvi4qvgiF9ngmEMQCi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamPoe/CSCI-290/blob/main/notebooks/asm_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ThC-lCa0kh35"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classification(df, target, method):\n",
        "  if method == \"gini\":\n",
        "    gini = 0\n",
        "    lowest_gini = float('inf')\n",
        "    split_point = 0\n",
        "    lowest_quant_gini = float('inf')\n",
        "    quant_attrib = ''\n",
        "    overall = len( df )\n",
        "    for attrib in df.columns: ### change this to df.columns ###\n",
        "      vals = df[attrib].unique()\n",
        "      # Quantitative Gini Impurity Calc\n",
        "      if df[attrib].dtype in ['float64', 'int64']:\n",
        "        if len( df[attrib].unique() ) > 10:\n",
        "          vals.sort()\n",
        "          overall = len( df )\n",
        "          gini_impurities = []\n",
        "          for val in vals:\n",
        "            quant_gini = 0\n",
        "            left = df[ df[attrib] <= val ][ [attrib,target] ]\n",
        "            props = left[ target ].value_counts( normalize = True )\n",
        "            weight = len( left ) / overall\n",
        "            for prop in props.array:\n",
        "              quant_gini += weight*(1-(prop**2))\n",
        "            right = df[ df[attrib] > val ][ [attrib,target] ]\n",
        "            props = right[ target ].value_counts( normalize = True )\n",
        "            weight = len( right ) / overall\n",
        "            for prop in props.array:\n",
        "              if prop > 0:\n",
        "                ### Change calculation ###\n",
        "                quant_gini += weight*(1-(prop**2))\n",
        "              gini_impurities.append(quant_gini)\n",
        "          index = pd.Series( gini_impurities ).idxmin()\n",
        "          # Check to see if there is a new lowest Gini Impurity\n",
        "          if gini_impurities[index] < lowest_quant_gini:\n",
        "            # Lowest Gini Impurity\n",
        "            lowest_quant_gini = gini_impurities[index]\n",
        "            # Split point with lowest Gini Impurity\n",
        "            split_point = vals[index]\n",
        "            # Attribute that has the split point\n",
        "            quant_attrib = attrib\n",
        "\n",
        "      # Categorical Gini Impurity Calc\n",
        "      else:\n",
        "        for val in vals:\n",
        "          subset_size = len(df[ df[attrib] == val ])\n",
        "          weight = subset_size / overall\n",
        "          props = df[ df[attrib] == val ][target].value_counts( normalize=True )\n",
        "          for p in props.array:\n",
        "            gini +=  weight*(1-(p**2))\n",
        "        if lowest_gini > gini:\n",
        "          lowest_gini = gini\n",
        "          lowest_attrib = attrib\n",
        "    # Compares the lowest categorical Gini Impurity with the lowest quantitative Gini Impurity\n",
        "    if lowest_gini < lowest_quant_gini:\n",
        "      # If categorical Gini Impurity is still lowest\n",
        "      return lowest_attrib, lowest_gini\n",
        "    else:\n",
        "      # If quantitative Gini Impurity is lowest\n",
        "      lowest_gini = lowest_quant_gini\n",
        "      lowest_attrib = quant_attrib\n",
        "      return lowest_attrib, split_point, lowest_gini\n",
        "  elif method == \"entropy\":\n",
        "    entropy = 0\n",
        "    lowest_entropy = float('inf')\n",
        "    split_point = 0\n",
        "    lowest_quant_entropy = float('inf')\n",
        "    quant_attrib = ''\n",
        "    overall = len( df )\n",
        "    for attrib in df.columns: ### change this to df.columns ###\n",
        "      vals = df[attrib].unique()\n",
        "      # Quantitative Entropy Calc\n",
        "      if df[attrib].dtype in ['float64', 'int64']:\n",
        "        if len( df[attrib].unique() ) > 10:\n",
        "          vals.sort()\n",
        "          overall = len( df )\n",
        "          entropies = []\n",
        "          for val in vals:\n",
        "            quant_entropy = 0\n",
        "            left = df[ df[attrib] <= val ][ [attrib,target] ]\n",
        "            props = left[ target ].value_counts( normalize = True )\n",
        "            weight = len( left ) / overall\n",
        "            for prop in props.array:\n",
        "              quant_entropy = quant_entropy - weight*prop*math.log2( prop )\n",
        "            right = df[ df[attrib] > val ][ [attrib,target] ]\n",
        "            props = right[ target ].value_counts( normalize = True )\n",
        "            weight = len( right ) / overall\n",
        "            for prop in props.array:\n",
        "              if prop > 0:\n",
        "                quant_entropy = quant_entropy - weight*prop*math.log2( prop )\n",
        "              entropies.append(quant_entropy)\n",
        "          index = pd.Series( entropies ).idxmin()\n",
        "          # Check to see if there is a new lowest Entropy\n",
        "          if entropies[index] < lowest_quant_entropy:\n",
        "            # Lowest entropy\n",
        "            lowest_quant_entropy = entropies[index]\n",
        "            # Split point with lowest entropy\n",
        "            split_point = vals[index]\n",
        "            # Attribute that has the split point\n",
        "            quant_attrib = attrib\n",
        "\n",
        "      # Categorical Entropy Calc\n",
        "      else:\n",
        "        for val in vals:\n",
        "          subset_size = len(df[ df[attrib] == val ])\n",
        "          weight = subset_size / overall\n",
        "          props = df[ df[attrib] == val ][target].value_counts( normalize=True )\n",
        "          for p in props.array:\n",
        "            entropy =  entropy - weight*(p*math.log2(p))\n",
        "        if lowest_entropy > entropy:\n",
        "          lowest_entropy = entropy\n",
        "          lowest_attrib = attrib\n",
        "    # Compares the lowest categorical Entropy with the lowest quantitative Entropy\n",
        "    if lowest_entropy < lowest_quant_entropy:\n",
        "      # If categorical entropy is still lowest\n",
        "      return lowest_attrib, lowest_entropy\n",
        "    else:\n",
        "      # If quantitative entropy is lowest\n",
        "      lowest_entropy = lowest_quant_entropy\n",
        "      lowest_attrib = quant_attrib\n",
        "      return lowest_attrib, split_point, lowest_entropy\n",
        "  else:\n",
        "    print(\"Invalid Method\")\n",
        "    return"
      ],
      "metadata": {
        "id": "agvv4BCspyNy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regression(df, target):\n",
        "  return"
      ],
      "metadata": {
        "id": "ixr2Qg7qpyQV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Attribute_selection_method(task, df, target):\n",
        "  ##train_set, test_set = train_test_split(df, test_size=0.2)\n",
        "\n",
        "  ### Add a Pipeline to process the data ###\n",
        "\n",
        "  if task.lower() == \"classification\":\n",
        "    method = input(\"Enter the method of attribute selection (gini or entropy): \").lower()\n",
        "    print(classification(df, target, method))\n",
        "  elif task.lower() == \"regression\":\n",
        "    print(regression(df, target))\n",
        "  else:\n",
        "    print(\"Invalid Task\")\n",
        "    return"
      ],
      "metadata": {
        "id": "poFj0ZAqnLbL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/WilliamPoe/CSCI-290/refs/heads/main/Data/ds_salaries.csv\") ## Dataset\n",
        "target = \"employee_residence\" ## Target attribute\n",
        "task = \"classification\" ## Classification or Regression\n",
        "Attribute_selection_method(task, df, target)"
      ],
      "metadata": {
        "id": "Q05dsZSeqN3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe29b2d-5a12-4b80-84e0-fa046e420932"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the method of attribute selection (gini or entropy): entropy\n",
            "('salary_in_usd', 111000, 0.2559790811041855)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Sy52pdE33K9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}